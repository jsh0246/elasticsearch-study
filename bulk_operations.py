from elasticsearch import Elasticsearch
from elasticsearch.helpers import bulk
import json
import random
from datetime import datetime, timedelta

# Elasticsearch ì—°ê²° ì„¤ì •
es = Elasticsearch(
    "http://localhost:9200",
    basic_auth=("elastic", "OBIpKj46")
)

def print_section(title):
    print("\n" + "="*50)
    print(f"ğŸ“¦ {title}")
    print("="*50)

def generate_sample_data(count=100):
    """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    categories = ['í”„ë¡œê·¸ë˜ë°', 'ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤', 'ì›¹ê°œë°œ', 'ë¨¸ì‹ ëŸ¬ë‹', 'ì¸ê³µì§€ëŠ¥', 'í´ë¼ìš°ë“œ', 'ë³´ì•ˆ', 'ëª¨ë°”ì¼']
    authors = ['ê¹€ì² ìˆ˜', 'ì´ì˜í¬', 'ë°•ë¯¼ìˆ˜', 'ìµœì§€ì€', 'ì •ë™í›ˆ', 'í™ê¸¸ë™', 'ê¹€ì˜ìˆ˜', 'ì´ë¯¼ì •']
    
    languages = ['Python', 'Java', 'JavaScript', 'C++', 'Go', 'Rust', 'TypeScript', 'Kotlin']
    adjectives = ['ì™„ë²½í•œ', 'ì‹¤ìš©ì ì¸', 'ì „ë¬¸ê°€ë¥¼ ìœ„í•œ', 'ì´ˆë³´ìë¥¼ ìœ„í•œ', 'ê³ ê¸‰', 'ê¸°ì´ˆ', 'ì‹¬í™”']
    
    data = []
    
    for i in range(count):
        # ëœë¤ ë°ì´í„° ìƒì„±
        category = random.choice(categories)
        author = random.choice(authors)
        language = random.choice(languages)
        adjective = random.choice(adjectives)
        
        # ë‚ ì§œ ë²”ìœ„ (ìµœê·¼ 2ë…„)
        start_date = datetime.now() - timedelta(days=730)
        random_days = random.randint(0, 730)
        pub_date = start_date + timedelta(days=random_days)
        
        doc = {
            "title": f"{adjective} {language} {category}",
            "author": author,
            "category": category,
            "language": language,
            "publish_date": pub_date.strftime("%Y-%m-%d"),
            "price": random.randint(15000, 50000),
            "pages": random.randint(200, 800),
            "rating": round(random.uniform(3.0, 5.0), 1),
            "description": f"{language}ë¥¼ ì‚¬ìš©í•œ {category} ì „ë¬¸ì„œì . {adjective} ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ì‹¤ë¬´ì— ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "tags": [language.lower(), category, "programming"] + random.sample(['tutorial', 'advanced', 'beginner', 'expert'], 2)
        }
        
        data.append(doc)
    
    return data

def main():
    print_section("ë²Œí¬ ì¸ë±ì‹± ì‹¤ìŠµ")
    
    index_name = "tech_books"
    
    # 1. ì¸ë±ìŠ¤ ì‚­ì œ ë° ì¬ìƒì„±
    print("ğŸ—‘ï¸ ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ...")
    if es.indices.exists(index=index_name):
        es.indices.delete(index=index_name)
        print(f"   '{index_name}' ì¸ë±ìŠ¤ ì‚­ì œ ì™„ë£Œ")
    
    # 2. ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ìƒì„± (í•œêµ­ì–´ ê²€ìƒ‰ ìµœì í™”)
    print("ğŸ—ï¸ ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ìƒì„±...")
    
    index_settings = {
        "settings": {
            "number_of_shards": 1,
            "number_of_replicas": 0,
            "analysis": {
                "analyzer": {
                    "korean_analyzer": {
                        "type": "standard",
                        "stopwords": "_none_"
                    }
                }
            }
        },
        "mappings": {
            "properties": {
                "title": {
                    "type": "text",
                    "analyzer": "korean_analyzer"
                },
                "author": {"type": "keyword"},
                "category": {"type": "keyword"},
                "language": {"type": "keyword"},
                "publish_date": {"type": "date"},
                "price": {"type": "integer"},
                "pages": {"type": "integer"},
                "rating": {"type": "float"},
                "description": {
                    "type": "text",
                    "analyzer": "korean_analyzer"
                },
                "tags": {"type": "keyword"}
            }
        }
    }
    
    es.indices.create(index=index_name, body=index_settings)
    print(f"   '{index_name}' ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
    
    # 3. ë²Œí¬ ë°ì´í„° ìƒì„±
    print("ğŸ“ ìƒ˜í”Œ ë°ì´í„° ìƒì„±...")
    sample_data = generate_sample_data(100)
    print(f"   {len(sample_data)}ê°œì˜ ìƒ˜í”Œ ë¬¸ì„œ ìƒì„± ì™„ë£Œ")
    
    # 4. ë²Œí¬ ì¸ë±ì‹±
    print("ğŸ“¦ ë²Œí¬ ì¸ë±ì‹± ì‹œì‘...")
    
    def doc_generator():
        for i, doc in enumerate(sample_data):
            yield {
                "_index": index_name,
                "_id": i + 1,
                "_source": doc
            }
    
    # ë²Œí¬ ì¸ë±ì‹± ì‹¤í–‰
    success_count, failed_docs = bulk(es, doc_generator(), chunk_size=50)
    print(f"   ì„±ê³µ: {success_count}ê°œ, ì‹¤íŒ¨: {len(failed_docs)}ê°œ")
    
    # 5. ì¸ë±ìŠ¤ ìƒˆë¡œê³ ì¹¨
    es.indices.refresh(index=index_name)
    print("ğŸ”„ ì¸ë±ìŠ¤ ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ")
    
    # 6. ì¸ë±ì‹± ê²°ê³¼ í™•ì¸
    print_section("ì¸ë±ì‹± ê²°ê³¼ í™•ì¸")
    
    total_count = es.count(index=index_name)
    print(f"ğŸ“Š ì´ ë¬¸ì„œ ìˆ˜: {total_count['count']}ê°œ")
    
    # 7. ì¹´í…Œê³ ë¦¬ë³„ ì§‘ê³„
    print_section("ì¹´í…Œê³ ë¦¬ë³„ ì§‘ê³„")
    
    category_agg = {
        "size": 0,
        "aggs": {
            "categories": {
                "terms": {
                    "field": "category",
                    "size": 10
                }
            },
            "languages": {
                "terms": {
                    "field": "language",
                    "size": 10
                }
            },
            "price_stats": {
                "stats": {
                    "field": "price"
                }
            }
        }
    }
    
    agg_result = es.search(index=index_name, body=category_agg)
    
    print("ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
    for bucket in agg_result['aggregations']['categories']['buckets']:
        print(f"   {bucket['key']}: {bucket['doc_count']}ê¶Œ")
    
    print("\nğŸ’» ì–¸ì–´ë³„ ë¶„í¬:")
    for bucket in agg_result['aggregations']['languages']['buckets']:
        print(f"   {bucket['key']}: {bucket['doc_count']}ê¶Œ")
    
    price_stats = agg_result['aggregations']['price_stats']
    print(f"\nğŸ’° ê°€ê²© í†µê³„:")
    print(f"   í‰ê· : {price_stats['avg']:,.0f}ì›")
    print(f"   ìµœì†Œ: {price_stats['min']:,.0f}ì›")
    print(f"   ìµœëŒ€: {price_stats['max']:,.0f}ì›")
    
    # 8. ë³µí•© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print_section("ë³µí•© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    
    complex_queries = [
        {
            "name": "Python ê´€ë ¨ ê³ ê°€ ë„ì„œ",
            "query": {
                "bool": {
                    "must": [
                        {"match": {"language": "Python"}}
                    ],
                    "filter": [
                        {"range": {"price": {"gte": 35000}}}
                    ]
                }
            }
        },
        {
            "name": "í‰ì  4.5 ì´ìƒ ì›¹ê°œë°œ ë„ì„œ",
            "query": {
                "bool": {
                    "must": [
                        {"match": {"category": "ì›¹ê°œë°œ"}}
                    ],
                    "filter": [
                        {"range": {"rating": {"gte": 4.5}}}
                    ]
                }
            }
        },
        {
            "name": "ìµœê·¼ 1ë…„ê°„ ì¶œê°„ëœ ë¨¸ì‹ ëŸ¬ë‹ ë„ì„œ",
            "query": {
                "bool": {
                    "must": [
                        {"match": {"category": "ë¨¸ì‹ ëŸ¬ë‹"}}
                    ],
                    "filter": [
                        {"range": {"publish_date": {"gte": "2023-01-01"}}}
                    ]
                }
            }
        }
    ]
    
    for query_info in complex_queries:
        result = es.search(index=index_name, body={"query": query_info["query"]})
        print(f"ğŸ” {query_info['name']}: {result['hits']['total']['value']}ê°œ")
        
        # ìƒìœ„ 3ê°œ ê²°ê³¼ í‘œì‹œ
        for hit in result['hits']['hits'][:3]:
            doc = hit['_source']
            print(f"   - {doc['title']} (ê°€ê²©: {doc['price']:,}ì›, í‰ì : {doc['rating']})")
    
    # 9. ìŠ¤í¬ë¡¤ API í…ŒìŠ¤íŠ¸ (ëŒ€ëŸ‰ ë°ì´í„° ì¡°íšŒ)
    print_section("ìŠ¤í¬ë¡¤ API í…ŒìŠ¤íŠ¸")
    
    scroll_query = {
        "query": {"match_all": {}},
        "size": 20  # í•œ ë²ˆì— 20ê°œì”©
    }
    
    result = es.search(index=index_name, body=scroll_query, scroll='2m')
    scroll_id = result['_scroll_id']
    
    total_processed = 0
    while len(result['hits']['hits']) > 0:
        total_processed += len(result['hits']['hits'])
        
        # ë‹¤ìŒ ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°
        result = es.scroll(scroll_id=scroll_id, scroll='2m')
        
        if len(result['hits']['hits']) == 0:
            break
    
    print(f"ğŸ“œ ìŠ¤í¬ë¡¤ë¡œ ì²˜ë¦¬ëœ ë¬¸ì„œ ìˆ˜: {total_processed}ê°œ")
    
    # ìŠ¤í¬ë¡¤ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬
    es.clear_scroll(scroll_id=scroll_id)
    
    print_section("âœ… ë²Œí¬ ì¸ë±ì‹± ì‹¤ìŠµ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 